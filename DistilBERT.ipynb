{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\DataScience2024\\Projekty\\Final_project\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix, recall_score, precision_score, f1_score, roc_curve, auc)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Dense, Dropout, BatchNormalization, Embedding, Flatten, Input, Concatenate)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1624/1624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13ms/step - accuracy: 0.8351 - loss: 0.3883 - val_accuracy: 0.9215 - val_loss: 0.2012 - learning_rate: 5.0000e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m1624/1624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9270 - loss: 0.1917 - val_accuracy: 0.9293 - val_loss: 0.1781 - learning_rate: 5.0000e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m1624/1624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9369 - loss: 0.1670 - val_accuracy: 0.9356 - val_loss: 0.1656 - learning_rate: 5.0000e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m1624/1624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9408 - loss: 0.1557 - val_accuracy: 0.9415 - val_loss: 0.1568 - learning_rate: 5.0000e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m1624/1624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9441 - loss: 0.1468 - val_accuracy: 0.9413 - val_loss: 0.1525 - learning_rate: 5.0000e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m1624/1624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9442 - loss: 0.1430 - val_accuracy: 0.9418 - val_loss: 0.1494 - learning_rate: 5.0000e-05\n",
      "Epoch 7/10\n",
      "\u001b[1m1624/1624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9461 - loss: 0.1404 - val_accuracy: 0.9463 - val_loss: 0.1473 - learning_rate: 5.0000e-05\n",
      "Epoch 8/10\n",
      "\u001b[1m1624/1624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9499 - loss: 0.1310 - val_accuracy: 0.9449 - val_loss: 0.1443 - learning_rate: 5.0000e-05\n",
      "Epoch 9/10\n",
      "\u001b[1m1624/1624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.1332 - val_accuracy: 0.9458 - val_loss: 0.1421 - learning_rate: 5.0000e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m1624/1624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9521 - loss: 0.1289 - val_accuracy: 0.9466 - val_loss: 0.1409 - learning_rate: 5.0000e-05\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Accuracy on test data: 0.9491\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFDistilBertModel, DistilBertTokenizer\n",
    "\n",
    "# Načtení modelu a tokenizéru\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = TFDistilBertModel.from_pretrained(model_name)\n",
    "\n",
    "# Funkce pro získání embeddingů v dávkách\n",
    "def get_distilbert_embeddings(texts, batch_size=16, max_length=128):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors='tf', max_length=max_length)\n",
    "        outputs = model(**inputs)\n",
    "        batch_embeddings = np.mean(outputs.last_hidden_state.numpy(), axis=1)  # Průměr posledních skrytých stavů\n",
    "        embeddings.append(batch_embeddings)\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# Funkce pro načtení a předzpracování dat\n",
    "def preprocess_data(df):\n",
    "    titles = df['title'].tolist()\n",
    "    X_title_distilbert = get_distilbert_embeddings(titles, batch_size=8)\n",
    "    return X_title_distilbert\n",
    "\n",
    "# Načtení a sloučení dat\n",
    "def load_and_merge_data(train_file, test_file, eval_file):\n",
    "    train_df = pd.read_csv(train_file, sep=';')\n",
    "    test_df = pd.read_csv(test_file, sep=';')\n",
    "    eval_df = pd.read_csv(eval_file, sep=';')\n",
    "    df_all = pd.concat([train_df, test_df, eval_df], ignore_index=True)\n",
    "    return df_all\n",
    "\n",
    "# Vytvoření modelu s fine-tuningem\n",
    "def create_model_with_finetuning(input_shape, num_classes):\n",
    "    input_layer = tf.keras.layers.Input(shape=(input_shape,), dtype=tf.float32, name=\"input_layer\")\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(input_layer)\n",
    "    output = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Trénování modelu\n",
    "def train_model(df_all):\n",
    "    X = preprocess_data(df_all)\n",
    "    Y = df_all['label'].astype(int).values  # Převedení labelů na čísla\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = create_model_with_finetuning(X_train.shape[1], len(set(Y)))\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=3, verbose=1)\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=16, validation_split=0.2, callbacks=[early_stopping, reduce_lr])\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy on test data: {accuracy:.4f}')\n",
    "\n",
    "# Načtení a trénování modelu\n",
    "df_all = load_and_merge_data('train (2).csv', 'test (1).csv', 'evaluation.csv')\n",
    "train_model(df_all)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
